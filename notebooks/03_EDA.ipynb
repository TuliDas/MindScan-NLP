{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "6PQHphKMQxxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KGqy3mvMq-p"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "\n",
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Counter for frequency counts\n",
        "from collections import Counter\n",
        "\n",
        "# WordCloud Visualization\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Text Feature Extraction and Statistical Analysis\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "# Word and Post Embeddings\n",
        "from gensim.models import Word2Vec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.manifold import TSNE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Dowmload and Loading\n",
        "\n",
        "Before loading the data, download the following files:  \n",
        "- [reddit_cleaned_ml.csv](https://github.com/TuliDas/MindScan-NLP/blob/main/data/reddit_cleaned_ml.csv)  \n",
        "- [reddit_cleaned_bert.csv](https://github.com/TuliDas/MindScan-NLP/blob/main/data/reddit_cleaned_bert.csv)  \n",
        "\n",
        "and upload them to your **Google Colab** environment.  \n"
      ],
      "metadata": {
        "id": "eMpd7dsZN_Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load cleaned dataset that prepared for both for ML and Bert model training\n",
        "df_cleaned_ml = pd.read_csv('/content/reddit_cleaned_ml.csv')\n",
        "df_cleaned_bert = pd.read_csv('/content/reddit_cleaned_bert.csv')"
      ],
      "metadata": {
        "id": "h3uCFuFGg4YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis (EDA)**\n",
        "\n",
        "This section explores the mental health Reddit dataset to understand its structure and characteristics before model training.\n",
        "\n",
        "**Steps included:**\n",
        "1. **Dataset Structure & Quality**: Inspect dataset size and missing values.  \n",
        "2. **Label Analysis**: Examine class distribution, percentage distribution to identify any imbalance.  \n",
        "3. **Text Characteristics**: Explore average words and characters per post, also in classes.\n",
        "4. **Word-Level Analysis**: Generate word clouds and top words(based of frequency) per class to see common and class-specific words.  \n",
        "5. **Lexical Diversity**: Compute unique words ratio per class to compare vocabulary richness.  \n",
        "6. **Statistical Distinctive Keywords**: Identify words most characteristic of each class using chi-square.  \n",
        "7. **Embedding Visualization**: Visualize semantic structure using Word2Vec + t-SNE and BERT embeddings + t-SNE.  \n"
      ],
      "metadata": {
        "id": "44Sm5qL5shOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Dataset Structure & Quality**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3T0nyD8zufsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Shape\n",
        "print(df_cleaned_ml.shape)\n",
        "print(df_cleaned_bert.shape)"
      ],
      "metadata": {
        "id": "M39x6NkqsgRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df_cleaned_ml.isnull().sum())\n",
        "print(df_cleaned_bert.isnull().sum())"
      ],
      "metadata": {
        "id": "DY3C0EHrvDBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Label Analysis**\n"
      ],
      "metadata": {
        "id": "wgywyKwQYcp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verify label distribition after cleaning\n",
        "class_counts = df_cleaned_ml['label'].value_counts()\n",
        "class_counts"
      ],
      "metadata": {
        "id": "-3G7NGvuBiEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output:** Class distribution\n",
        "\n",
        "| label      | count |\n",
        "|------------|------:|\n",
        "| ADHD       | 2000  |\n",
        "| Addiction  | 2000  |\n",
        "| Anxiety    | 2000  |\n",
        "| Depression | 2000  |\n",
        "| Normal     | 2000  |\n",
        "| OCD        | 2000  |\n",
        "| PTSD       | 2000  |\n",
        "| Suicidal   | 1913  |\n",
        "\n",
        "Total: 15913 rows\n"
      ],
      "metadata": {
        "id": "2tCDfyT7a6uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bar plots of each class distribution\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette=\"viridis\")\n",
        "plt.title('Number of posts per class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K_cqhpTEYtp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output:\n",
        "[Barplot-Number of posts per class.png](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/barplots-histplots/posts_per_class_barplot.png)"
      ],
      "metadata": {
        "id": "sdZOb2anb5bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage Distribution\n",
        "\n",
        "# Calculate Percentage\n",
        "class_percentages = df_cleaned_ml['label'].value_counts(normalize=True)*100\n",
        "\n",
        "# Convert to Dataframe for better visualization\n",
        "class_percentages_df = class_percentages.reset_index()\n",
        "class_percentages_df.columns = ['Class', 'Percentage']\n",
        "class_percentages_df\n"
      ],
      "metadata": {
        "id": "0v23ZZqxaqeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :** Class distribution (percentage)\n",
        "\n",
        "| Class      | Percentage |\n",
        "|------------|-----------:|\n",
        "| ADHD       | 12.57%    |\n",
        "| Addiction  | 12.57%    |\n",
        "| Anxiety    | 12.57%    |\n",
        "| Depression | 12.57%    |\n",
        "| Normal     | 12.57%    |\n",
        "| OCD        | 12.57%    |\n",
        "| PTSD       | 12.57%    |\n",
        "| Suicidal   | 12.02%    |\n"
      ],
      "metadata": {
        "id": "Xu3aI9CwdAHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Text Characteristics**"
      ],
      "metadata": {
        "id": "JE-dJr3ubvWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of words and characters per post\n",
        "df_cleaned_ml['num_words'] = df_cleaned_ml['text'].apply(lambda x: len(x.split()))\n",
        "df_cleaned_ml['num_chars'] = df_cleaned_ml['text'].apply(len)\n",
        "df_cleaned_ml"
      ],
      "metadata": {
        "id": "r-9vWLYbbQaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :** (ml_cleaned_dataset)\n",
        "\n",
        "| text | label | num_words | num_chars |\n",
        "|------|-------|-----------|-----------|\n",
        "| small success finally fill ice cube tray pre... | ADHD | 47 | 330 |\n",
        "| adderall shiver shakiness anybody experience s... | ADHD | 28 | 192 |\n",
        "| constant mental exhaustion relate undereate ... | ADHD | 53 | 369 |\n",
        "| get consistent nighttime route finally hate no... | ADHD | 41 | 255 |\n",
        "| actual lifestyle advice tired post subreddit s... | ADHD | 27 | 216 |\n",
        "| ... | ... | ... | ... |\n",
        "| not leave know lot people suicide selfish hone... | Suicidal | 26 | 155 |\n",
        "| ahh ahhim freaking world help | Suicidal | 5 | 31 |\n",
        "| lose girlfriend year lose yesterday hang b... | Suicidal | 58 | 374 |\n",
        "| lose friend trigger friend recently move text ... | Suicidal | 47 | 289 |\n",
        "| m feel lose feel discouraged tired comp... | Suicidal | 46 | 288 |\n"
      ],
      "metadata": {
        "id": "4qaLAEdmFeol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms plot of number of word per post (ML_Cleaned_Dataset)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.histplot(df_cleaned_ml['num_words'], bins=50, kde=True, color='skyblue', label='ML')\n",
        "plt.title('Distribution of Number of Words per Post (ML-Cleaned-Dataset)')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dW_Lw7uKo8nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :**\n",
        "[histplot-words-per-post-ml](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/barplots-histplots/histplot-words-per-post-ml.png)"
      ],
      "metadata": {
        "id": "m2ofJhiZudEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(x='label', y='num_words', data= df_cleaned_ml,palette='Set2')\n",
        "plt.title('Distribution of Word Count Per Class (ML-Cleaned-dataset)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Words')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F7F9KcP2jWQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output:**\n",
        "[boxplot-word-count-per-class-ml](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/barplots-histplots/boxplot-word-count-per-class-ml.png)"
      ],
      "metadata": {
        "id": "fVs70s5Ku0d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of words and characters per post\n",
        "df_cleaned_bert['num_words'] = df_cleaned_bert['text'].apply(lambda x: len(x.split()))\n",
        "df_cleaned_bert['num_chars'] = df_cleaned_bert['text'].apply(len)\n",
        "df_cleaned_bert"
      ],
      "metadata": {
        "id": "OLwAIEi4j2bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :** (Bert_Cleaned_Dataset)\n",
        "\n",
        "| text | label | num_words | num_chars |\n",
        "|------|-------|-----------|-----------|\n",
        "| small success: i finally filled the ice cube t... | ADHD | 113 | 599 |\n",
        "| adderall shivers/shakiness has anybody experie... | ADHD | 62 | 350 |\n",
        "| could my constant mental exhaustion be related... | ADHD | 158 | 831 |\n",
        "| i’ve been getting into a consistent nighttime ... | ADHD | 97 | 495 |\n",
        "| actual lifestyle advice i’m so tired of every ... | ADHD | 53 | 345 |\n",
        "| ... | ... | ... | ... |\n",
        "| why cant i leave i know a lot of people call s... | Suicidal | 70 | 321 |\n",
        "| ahhhhhhhhhhhhhhhhhhhh ahhhhhhhhhim so freaking... | Suicidal | 11 | 83 |\n",
        "| just lost my girlfriend of almost 4 years i lo... | Suicidal | 170 | 829 |\n",
        "| might lose a friend and it’s triggering me my ... | Suicidal | 108 | 542 |\n",
        "| 30m feeling lost i feel discouraged, tired, an... | Suicidal | 99 | 491 |\n"
      ],
      "metadata": {
        "id": "xI-VV66jGEtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.histplot(df_cleaned_bert['num_words'], bins=50, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Number of Words per Post (BERT)')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XHGpKd0ii44v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output:**\n",
        "[histplot-word-per-post-bert.png](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/barplots-histplots/histplot-word-per-post-bert.png)"
      ],
      "metadata": {
        "id": "R0V8twcOvNGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(x='label', y='num_words', data= df_cleaned_bert,palette='Set2')\n",
        "plt.title('Distribution of Word Count Per Class (BERT)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Words')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cqZf6VwQkOXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output:**\n",
        "[boxplot-word-count-per-class-bert.png](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/barplots-histplots/boxplot-word-count-per-class-bert.png)"
      ],
      "metadata": {
        "id": "N44csgW_vZAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average text length per class\n",
        "\n",
        "avg_words = df_cleaned_ml.groupby('label')['num_words'].mean()\n",
        "avg_chars = df_cleaned_ml.groupby('label')['num_chars'].mean()\n",
        "print(f\"Average word per class (cleaned_text_ml) : {avg_words}\")\n",
        "print(f\"\\nAverage char per class (cleaned_text_ml) : {avg_chars}\")"
      ],
      "metadata": {
        "id": "SeTU6muzkMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output** :  Text Statistics per Class (ML Cleaned Text)\n",
        "\n",
        "##### Average Words per Post\n",
        "| Label       | Avg. Words |\n",
        "|------------|-----------:|\n",
        "| ADHD       | 44.63     |\n",
        "| Addiction  | 35.34     |\n",
        "| Anxiety    | 37.05     |\n",
        "| Depression | 35.14     |\n",
        "| Normal     | 38.80     |\n",
        "| OCD        | 34.77     |\n",
        "| PTSD       | 37.09     |\n",
        "| Suicidal   | 35.58     |\n",
        "\n",
        "##### Average Characters per Post\n",
        "| Label       | Avg. Characters |\n",
        "|------------|----------------:|\n",
        "| ADHD       | 307.42          |\n",
        "| Addiction  | 235.16          |\n",
        "| Anxiety    | 248.78          |\n",
        "| Depression | 229.51          |\n",
        "| Normal     | 259.75          |\n",
        "| OCD        | 232.54          |\n",
        "| PTSD       | 252.31          |\n",
        "| Suicidal   | 230.25          |\n"
      ],
      "metadata": {
        "id": "EZhE5fhLwLtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_words = df_cleaned_bert.groupby('label')['num_words'].mean()\n",
        "avg_chars = df_cleaned_bert.groupby('label')['num_chars'].mean()\n",
        "print(f\"Average word per class (cleaned_text_bert) : {avg_words}\")\n",
        "print(f\"\\nAverage char per class (cleaned_text_bert) : {avg_chars}\")"
      ],
      "metadata": {
        "id": "Fbqv6bP_lMU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Word-Level Analysis**"
      ],
      "metadata": {
        "id": "CbwaW_98nug_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- 1. Word Clouds for Each Class -------------\n",
        "\n",
        "def plot_wordcloud(class_name, text):\n",
        "  wc = WordCloud( width=800, height=400, max_words= 100,\n",
        "                 background_color= 'white', colormap = 'viridis').generate(\" \".join(text))\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.imshow(wc, interpolation='bilinear')\n",
        "  plt.axis('off')\n",
        "  plt.title(f'Word Cloud for Class: {class_name}', fontsize = 16)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "S6DFJz8xlP3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Word Cloud\n",
        "for label in df_cleaned_ml['label'].unique():\n",
        "  labeled_text = df_cleaned_ml[df_cleaned_ml['label'] == label]['text']\n",
        "  plot_wordcloud(label, labeled_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "E7wryKzXpc1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------- 2.Top N Most Frequent Words per Class --------\n",
        "def top_words_per_class(df, label, N = 20):\n",
        "  words = df[df['label'] == label]['text'].str.lower().str.cat(sep=' ').split()\n",
        "  counter = Counter(words)\n",
        "  return counter.most_common(N)\n"
      ],
      "metadata": {
        "id": "FjbffPOYrCK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in df_cleaned_ml['label'].unique():\n",
        "  top_words = top_words_per_class(df_cleaned_ml, label)\n",
        "  print(f\"\\nTop {len(top_words)} words for class {label}: {top_words}\")"
      ],
      "metadata": {
        "id": "B8qY_GS31YZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Output :** Top 20 Frequent Words per Class (without frequency counts)  \n",
        "\n",
        "**ADHD:**  \n",
        "not, adhd, like, feel, know, work, time, day, thing, get, want, help, start, try, take, think, med, medication, go, people  \n",
        "\n",
        "**Addiction:**  \n",
        "not, day, feel, year, quit, like, drink, time, go, want, know, smoke, get, today, sober, think, month, life, no, stop  \n",
        "\n",
        "**Anxiety:**  \n",
        "not, feel, anxiety, like, panic, attack, know, go, think, people, day, time, get, bad, want, help, start, thing, work, anxious  \n",
        "\n",
        "**Depression:**  \n",
        "not, feel, like, want, know, life, go, no, people, think, time, depression, get, day, thing, help, friend, try, year, bad  \n",
        "\n",
        "**Normal:**  \n",
        "not, like, lpt, feel, time, day, get, good, work, want, people, go, know, year, think, happy, thing, love, life, today  \n",
        "\n",
        "**OCD:**  \n",
        "not, ocd, like, feel, thought, know, think, thing, want, bad, help, intrusive, time, get, go, try, day, tell, people, anxiety  \n",
        "\n",
        "**PTSD:**  \n",
        "not, feel, like, ptsd, know, want, time, trauma, think, help, get, year, go, thing, trigger, people, happen, bad, try, day  \n",
        "\n",
        "**Suicidal:**  \n",
        "not, feel, want, know, life, like, go, think, no, year, die, day, time, suicide, people, kill, get, love, live, friend  \n"
      ],
      "metadata": {
        "id": "nl9uS6lDpsV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Common Words Removal for clear wordcloud\n",
        "\n",
        "- For **EDA only**: Remove **common words and stopwords** to focus on class-distinctive words."
      ],
      "metadata": {
        "id": "_ffya-ygjRXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common words to remove for EDA only\n",
        "common_words = set([\n",
        "    'work', 'today', 'year', 'day', 'thing',\n",
        "    'like', 'feel', 'know', 'want', 'time', 'go',\n",
        "    'think', 'get', 'take', 'people' , 'life' , 'start',\n",
        "    'help' , 'try' , 'good' , 'bad' ,\n",
        "    'need' , 'tell' , 'way' ,\n",
        "    'no', 'not' , 'never', 'nor'  # also added negations\n",
        "])\n",
        "\n",
        "# Create a temporary copy for EDA\n",
        "eda_texts = df_cleaned_ml.copy()\n",
        "\n",
        "def filter_text_for_eda(text):\n",
        "    words = text.split()\n",
        "    filtered = [w for w in words if w not in common_words]\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "eda_texts['text'] = eda_texts['text'].apply(filter_text_for_eda)\n"
      ],
      "metadata": {
        "id": "DZmAef4fmTWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Word Cloud\n",
        "for label in eda_texts['label'].unique():\n",
        "  labeled_text = eda_texts[eda_texts['label'] == label]['text']\n",
        "  plot_wordcloud(label, labeled_text)"
      ],
      "metadata": {
        "id": "MpYWhJUHoP71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output**\n",
        "[word_clouds.png for each class/label](https://github.com/TuliDas/MindScan-NLP/tree/main/images/eda/wordclouds)"
      ],
      "metadata": {
        "id": "v5WLATF60ro_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for label in eda_texts['label'].unique():\n",
        "  top_words = top_words_per_class(eda_texts, label)\n",
        "  print(f\"\\nTop {len(top_words)} words for class {label}: {top_words}\")"
      ],
      "metadata": {
        "id": "VCzI1XABpnrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Top 20 Words per Class (Words Only)**\n",
        "\n",
        "#####**ADHD**\n",
        "adhd, med, medication, find, diagnose, mg, experience, adderall, month, week, long, focus, lot, make, say, anxiety, hour, look, struggle, school\n",
        "\n",
        "#####**Addiction**\n",
        "quit, drink, smoke, sober, month, stop, week, addiction, long, thank, alcohol, cigarette, hard, nicotine, well, night, ago, clean, friend, drug\n",
        "\n",
        "#####**Anxiety**\n",
        "anxiety, panic, attack, anxious, heart, social, have, make, symptom, happen, talk, health, come, friend, stop, look, experience, die, say, week\n",
        "\n",
        "#####**Depression**\n",
        "depression, friend, anymore, hate, well, talk, live, depressed, tired, end, love, hard, care, happy, make, find, die, thought, stop, long\n",
        "\n",
        "#####**Normal**\n",
        "lpt, happy, love, friend, look, s, find, lot, say, edit, make, new, come, thank, ask, little, old, talk, see, post\n",
        "\n",
        "#####**OCD**\n",
        "ocd, thought, intrusive, anxiety, compulsion, stop, make, happen, have, find, say, fear, come, person, look, brain, right, head, experience, lot\n",
        "\n",
        "#####**PTSD**\n",
        "ptsd, trauma, trigger, happen, experience, flashback, have, nightmare, therapy, sleep, talk, find, therapist, come, friend, lot, hard, anxiety, stop, make\n",
        "\n",
        "#####**Suicidal**\n",
        "die, suicide, kill, love, live, friend, find, lose, end, wish, hate, anymore, well, leave, family, fuck, brother, month, miss, say"
      ],
      "metadata": {
        "id": "IeWf6q2H1bdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Lexical Diversity**\n",
        "\n",
        "\n",
        "Common metric:\n",
        "\n",
        "Lexical Diversity (TTR) =\n",
        "Number of Unique Words /\n",
        "Total Number of Words\n"
      ],
      "metadata": {
        "id": "6CHtzGiyHHWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical_diversity(text):\n",
        "  tokens = text.split()\n",
        "  if len(tokens) == 0:\n",
        "    return 0\n",
        "  return len(set(tokens)) / len(tokens)"
      ],
      "metadata": {
        "id": "yOHAHa_YHGrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned_ml['lexical_diversity'] = df_cleaned_ml['text'].apply(lexical_diversity)\n",
        "lexical_scores_ml = df_cleaned_ml.groupby('label')['lexical_diversity'].mean().reset_index()\n",
        "lexical_scores_ml"
      ],
      "metadata": {
        "id": "ahSa3CQ5tGO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :** for df_cleaned_ml data  \n",
        "\n",
        "| Label      | Lexical Diversity |\n",
        "|------------|-------------------|\n",
        "| ADHD       | 0.799321          |\n",
        "| Addiction  | 0.837921          |\n",
        "| Anxiety    | 0.810511          |\n",
        "| Depression | 0.813238          |\n",
        "| Normal     | 0.818335          |\n",
        "| OCD        | 0.799929          |\n",
        "| PTSD       | 0.823304          |\n",
        "| Suicidal   | 0.823510          |"
      ],
      "metadata": {
        "id": "fsEH7Nv3KAI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned_bert['lexical_diversity'] = df_cleaned_bert['text'].apply(lexical_diversity)\n",
        "lexical_scores_bert = df_cleaned_bert.groupby('label')['lexical_diversity'].mean().reset_index()\n",
        "lexical_scores_bert"
      ],
      "metadata": {
        "id": "-_L6dvvuEvDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :** for df_cleaned_bert data  \n",
        "\n",
        "| Label      | Lexical Diversity |\n",
        "|------------|-------------------|\n",
        "| ADHD       | 0.742390          |\n",
        "| Addiction  | 0.795363          |\n",
        "| Anxiety    | 0.770159          |\n",
        "| Depression | 0.753351          |\n",
        "| Normal     | 0.775004          |\n",
        "| OCD        | 0.762195          |\n",
        "| PTSD       | 0.768020          |\n",
        "| Suicidal   | 0.763578          |\n"
      ],
      "metadata": {
        "id": "UWgoTbOGKF6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Lexical diversity of both dataset\n",
        "\n",
        "ml_scores = {}\n",
        "for index, row in lexical_scores_ml.iterrows():\n",
        "  ml_scores[row['label']] = row['lexical_diversity']\n",
        "\n",
        "bert_scores = {}\n",
        "for index, row in lexical_scores_bert.iterrows():\n",
        "  bert_scores[row['label']] = row['lexical_diversity']\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "df_plot = pd.DataFrame({\n",
        "    \"ML_cleaned\": ml_scores,\n",
        "    \"BERT_data\": bert_scores\n",
        "}).T  # transpose to get labels as rows\n",
        "\n",
        "df_plot = df_plot.T  # flip back so classes are x-axis\n",
        "\n",
        "# Plot\n",
        "ax = df_plot.plot(kind=\"bar\", figsize=(10,6), width=0.8)\n",
        "\n",
        "plt.title(\"Lexical Diversity Comparison by Class\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Lexical Diversity Score\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Dataset\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7siFcItVF-K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[lexical-diversity-comparison-by-class](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/barplots-histplots/lexical-diversity-comparison-by-class.png)"
      ],
      "metadata": {
        "id": "YbcWnaY7JhYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Statistical Distinctive word(Chi-Square)**\n",
        "- Chi-Square test measures the association between a word and a class.  \n",
        "- Words with high Chi-Square scores are more distinctive for that class compared to others.\n"
      ],
      "metadata": {
        "id": "si_GeJrBCFCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
        "X = vectorizer.fit_transform(df_cleaned_ml['text'])\n",
        "y = df_cleaned_ml['label']\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "distinctive_words = {}\n",
        "\n",
        "for label in df_cleaned_ml['label'].unique():\n",
        "  chi2_scores , p_values = chi2(X, (y == label))\n",
        "  scores = list(zip(feature_names,chi2_scores))\n",
        "\n",
        "  sorted_scores = sorted(scores, key = lambda x: x[1] , reverse=True)\n",
        "  distinctive_words[label] = sorted_scores[:15]"
      ],
      "metadata": {
        "id": "6FNdQvYPNlpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show top distinctive words per class\n",
        "for label, words in distinctive_words.items():\n",
        "    print(f\"\\nTop distinctive words for {label}:\")\n",
        "    print([w for w, s in words])"
      ],
      "metadata": {
        "id": "X8jQpQM3dY01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output : Top Distinctive Words per Class**\n",
        "\n",
        "- **ADHD:**  \n",
        "  adhd, adderall, med, medication, vyvanse, mg, concerta, diagnose, stimulant, focus, xr, ritalin, task, work, diagnosis  \n",
        "\n",
        "- **Addiction:**  \n",
        "  quit, sober, smoke, drink, addiction, nicotine, cigarette, day, alcohol, craving, iwndwyt, smoking, sobriety, addict, relapse  \n",
        "\n",
        "- **Anxiety:**  \n",
        "  anxiety, panic, attack, anxious, heart, social, ha, health, symptom, chest, ocd, palpitation, adhd, calm, breath  \n",
        "\n",
        "- **Depression:**  \n",
        "  depression, depressed, anymore, don, feel, want, ocd, life, antidepressant, tired, hate, adhd, care, sad, loser  \n",
        "\n",
        "- **Normal:**  \n",
        "  lpt, happy, edit, feel, anxiety, ocd, buy, save, adhd, travel, thought, small, item, bad, award  \n",
        "\n",
        "- **OCD:**  \n",
        "  ocd, thought, intrusive, compulsion, obsession, pocd, theme, erp, contamination, obsessive, hocd, false, fear, obsess, harm  \n",
        "\n",
        "- **PTSD:**  \n",
        "  ptsd, trauma, flashback, trigger, nightmare, abuse, assault, traumatic, emdr, therapy, abuser, therapist, sexual, tw, sexually  \n",
        "\n",
        "- **Suicidal:**  \n",
        "  suicide, kill, die, brother, grief, life, commit, miss, death, suicidal, dad, wish, son, anxiety, pain  "
      ],
      "metadata": {
        "id": "swO7aR5MCBBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_distinctive_words(distinctive_words, top_n=10):\n",
        "    \"\"\"\n",
        "    Plot bar charts of top distinctive words per class (Chi-Square scores).\n",
        "    \"\"\"\n",
        "    for label, words_scores in distinctive_words.items():\n",
        "        words, scores = zip(*words_scores[:top_n])\n",
        "\n",
        "        plt.figure(figsize=(10,6))\n",
        "        plt.barh(words, scores, color=\"skyblue\")\n",
        "        plt.gca().invert_yaxis()  # highest score at top\n",
        "        plt.title(f\"Top {top_n} Distinctive Words for {label}\", fontsize=14)\n",
        "        plt.xlabel(\"Chi-Square Score\", fontsize=12)\n",
        "        plt.ylabel(\"Words\", fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "zomSh2bjfquY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_distinctive_words(distinctive_words, top_n=10)\n"
      ],
      "metadata": {
        "id": "ugZ1qWwSf7fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :** Barplots\n",
        "- repo folder link : ['class/label'-distinctive-class-barplots](https://github.com/TuliDas/MindScan-NLP/tree/main/images/eda/distinctive-words)\n"
      ],
      "metadata": {
        "id": "50UoNbZXA4n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**7. Embedding visualization**"
      ],
      "metadata": {
        "id": "pscC6U4wCSvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Embedding (word2Vec , t-TSNE)**\n",
        "- **Word2Vec:** Converts words into dense numerical vectors such that semantically similar words are closer in vector space.  \n",
        "- **t-SNE:** A dimensionality reduction technique that projects high-dimensional word vectors into 2D or 3D for visualization.  \n",
        "- **Purpose in EDA:** Visualize how words from different classes group together and see semantic relationships or overlaps between classes.\n"
      ],
      "metadata": {
        "id": "K0vSunviOCKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prepare corpus (tokenized texts)\n",
        "corpus = [text.split() for text in df_cleaned_ml['text']]\n",
        "\n",
        "# 2. Train Word2Vec\n",
        "model = Word2Vec(\n",
        "    sentences=corpus,\n",
        "    vector_size=100,  # embedding dimensions\n",
        "    window=5,\n",
        "    min_count=2,      # ignore words with total freq < 2\n",
        "    workers=4,\n",
        "    sg=1              # skip-gram model\n",
        ")\n",
        "\n",
        "\n",
        "# 4. Collect embeddings for top words\n",
        "words = []\n",
        "labels = []\n",
        "for i, (cls, top_words) in enumerate(distinctive_words.items()):\n",
        "    for word, score in top_words:\n",
        "        if word in model.wv.key_to_index:   # ensure word exists in vocab\n",
        "            words.append(model.wv[word])\n",
        "            labels.append((word, cls))\n",
        "\n",
        "# Convert to DataFrame\n",
        "word_vectors = pd.DataFrame(words)\n",
        "word_labels = pd.DataFrame(labels, columns=[\"word\", \"class\"])\n",
        "\n",
        "# 5. Reduce dimension with t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=10)\n",
        "embeddings_2d = tsne.fit_transform(word_vectors)\n",
        "\n",
        "# 6. Plot with colors per class\n",
        "plt.figure(figsize=(12, 8))\n",
        "unique_classes = word_labels['class'].unique()\n",
        "palette = sns.color_palette(\"tab10\", len(unique_classes))\n",
        "\n",
        "for i, cls in enumerate(unique_classes):\n",
        "    idx = word_labels['class'] == cls   # idx is all selected rows of current selected class/label\n",
        "    plt.scatter(embeddings_2d[idx, 0],   # x-coordinates of current label/class's words\n",
        "                embeddings_2d[idx, 1],   # y-coordinates of current label/class's words\n",
        "                label=cls,\n",
        "                color=palette[i],\n",
        "                alpha=0.7, s=60)\n",
        "    # plot the words\n",
        "    for (x, y), word in zip(embeddings_2d[idx], word_labels[idx]['word']):\n",
        "        plt.text(x+0.02, y+0.02, word, fontsize=9)\n",
        "\n",
        "plt.legend(title=\"Class\")\n",
        "plt.title(\"t-SNE Visualization of Top Words per Class (Word2Vec)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5dNnheJRWNyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output :**\n",
        "[t-SNE Visualization of Top Distinctive Words per Class (Word2Vec).png](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/embeddings/Word2Vec_tSNE_top_distinctive_words_visualization.png)\n",
        "#### **Observation :**\n",
        "- Most words from ADHD, Addiction, Suicidal, Depression, Anxiety, and Normal classes cluster together.  \n",
        "- PTSD and OCD words are closer to each other, with some overlap with Normal class words.  "
      ],
      "metadata": {
        "id": "mVxsSRutrz6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentence/Post BERT Embeddings (t-SNE Visualization)**\n",
        "\n",
        "- Generate sentence embeddings using **BERT** for each post.  \n",
        "- Apply **t-SNE** to reduce high-dimensional embeddings to 2D for visualization.  \n",
        "- **Purpose in EDA:** Observe how posts from different mental health classes cluster in semantic space, and identify overlaps or distinct groups.\n"
      ],
      "metadata": {
        "id": "3WKxxgFZsISV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: BERT embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')  # light + fast\n",
        "X_bert = model.encode(df_cleaned_bert['text'].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Step 2: t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "X_tsne = tsne.fit_transform(X_bert)\n",
        "\n",
        "# Step 3: Plot\n",
        "plt.figure(figsize=(10,7))\n",
        "for label in df_cleaned_bert['label'].unique():\n",
        "    idx = df_cleaned_bert['label'] == label\n",
        "    plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1], label=label, alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title(\"BERT + t-SNE: Post Embeddings\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w0FW8sMTsiM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output:**\n",
        "[BERT + t-SNE -Post Embeddings.png](https://github.com/TuliDas/MindScan-NLP/blob/main/images/eda/embeddings/BERT_tSNE_Post_Embeddings.png)\n",
        "#### **Observation:**\n",
        "- The BERT-based t-SNE visualization of post embeddings reveals clear separations for several classes. ADHD, Addiction, OCD, PTSD, and Normal form distinguishable clusters.\n",
        "- Anxiety also forms a visible cluster, although some PTSD posts overlap into this region.\n",
        "- However, Depression and Suicidal classes show significant overlap, suggesting strong semantic similarity in the way users express these two conditions. This overlap may explain why models could struggle to differentiate between them."
      ],
      "metadata": {
        "id": "PHmvl9IRMePs"
      }
    }
  ]
}
